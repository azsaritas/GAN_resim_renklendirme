{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7ce96b0-9fdd-4716-9d5a-849e94f13d94",
   "metadata": {},
   "source": [
    "# -GAN kullanrak resim renklendirme - Image Colorization using GAN \n",
    "#### Generative Adversarial Networks iki temel yapıdan oluşur. Generator (Üretici) ve Discriminator (Ayırıcı). Generator bir veri üretir ve Discriminator üretilen bu verini gerçek mi yoksa sahte mi olduğunu anlamaya çalışır. Bu geri bildirimle Disciriminator her zaman gerçek veriye yaklaşmaya çalışır ve bu sayede Generator zamanla gerçeğe yakın veriler üretmeye başlar.\n",
    "#### Bu projede önce manzara resimlerinin bulunduğu verisetindeki görsellerin bir kısmı L*a*b formatında siyah beyaz hale dönüşütürlür. Generator bu şekilde yeni görseller üretmeye çalışır. Discirminator elindeki renkli verilerle Generator tarafınfan üretilen yeni resimleri karşılaştırır. Ve renkli resimşler göre hata hesabı yapar. Bu sayede bir süre sonra Generator siyah beyaz resimlerin renklerini tahmin etmeye başlar ve gerçeğe yakın sonuçlar üretir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c97ff2d-a34e-4c92-8e25-e0a10c5b7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #cuda aktifleştirme\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90971e68-ce1e-4a09-8bbf-217cbf6ccbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#veriseti işlemleri\n",
    "class ColorizationDataset(Dataset):  \n",
    "    def __init__(self, paths, split='train'): #veri setinin train kısmı alınır\n",
    "        self.splits = split\n",
    "        self.paths = paths\n",
    "        self.transforms = transforms.Compose([ #transforms modülü ile 256x256 olarak boyutlandırılır\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomHorizontalFlip(), #resimler yatay olarak ters çevrilir\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\") #resimler önce rgb formatına dönüştürülür\n",
    "        img = self.transforms(img)\n",
    "        img = np.array(img)\n",
    "        img_lab = rgb2lab(img).astype(\"float32\") #rgb formatından lab formantına (l: siyah, ab:renkli kısım) dönüştürülür\n",
    "        img_lab = transforms.ToTensor()(img_lab)\n",
    "        L = img_lab[[0], ...] / 50. - 1.\n",
    "        ab = img_lab[[1, 2], ...] / 110.\n",
    "        return {'L': L, 'ab': ab}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daaac38-c424-4aac-934b-b3c6b68b977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\azsar\\Desktop\\manzaralar\" #dosya yolu\n",
    "resimler = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg')] #resimleri okuma\n",
    "train_paths, val_paths = train_test_split(resimler, test_size=0.2, random_state=99) #verisetini train ve test olarak ayırma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a36bf-2dde-4f21-8604-f03336cb3eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(ColorizationDataset(train_paths), batch_size=16, shuffle=True) #train kısmını yüklme (16 şar batch olarak)\n",
    "test_dataloader = DataLoader(ColorizationDataset(val_paths, split='val'), batch_size=16, shuffle=True) #test kısmını yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6be6b-bd39-4a71-b23a-10e960328367",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module): #GAN yapısının generator (resim üretici) kısmı \n",
    "    def __init__(self, input_c=1, output_c=2, num_filters=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential( #konvolüsyon katmanları ileri ve geri konvolüsyon işlmei yapılıyoır\n",
    "            #konvolüsyon\n",
    "            nn.Conv2d(input_c, num_filters, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            \n",
    "            nn.Conv2d(num_filters, num_filters*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_filters*2),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            \n",
    "            nn.Conv2d(num_filters*2, num_filters*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_filters*4),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            \n",
    "            nn.Conv2d(num_filters*4, num_filters*8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_filters*8),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            #ters konvolüsyon\n",
    "            nn.ConvTranspose2d(num_filters*8, num_filters*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_filters*4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(num_filters*4, num_filters*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_filters*2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(num_filters*2, num_filters, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(num_filters, output_c, kernel_size=4, stride=2, padding=1), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "#GAN yapsının discriminator (ayırıcı-gerçek sahte tespit edici) kısmı\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_c=3, num_filters=64, n_down=3):\n",
    "        super().__init__()\n",
    "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
    "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) \n",
    "                  for i in range(n_down)]\n",
    "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)]\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True):\n",
    "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]\n",
    "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a062b8-90dc-4a2c-ad4b-b16914a594bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module): #GAN doğruluk değeri hesaplama işlemleri\n",
    "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(real_label)) #discriminator'ün fake-real tanımlaması\n",
    "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
    "        \n",
    "        self.loss = nn.BCEWithLogitsLoss() #loss fonksiyonu\n",
    "        \n",
    "    def get_labels(self, preds, target_is_real):\n",
    "        if target_is_real:\n",
    "            labels = self.real_label\n",
    "        else:\n",
    "            labels = self.fake_label\n",
    "        return labels.expand_as(preds)\n",
    "\n",
    "    def __call__(self, preds, target_is_real):\n",
    "        labels = self.get_labels(preds, target_is_real)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34f67d-a7a8-4c1b-9f4b-0a0ce600dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainModel(nn.Module): #GAN'ın çalıştırıldığı bölüm\n",
    "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4, \n",
    "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.lambda_L1 = lambda_L1\n",
    "        \n",
    "        if net_G is None:\n",
    "            self.net_G = Generator(input_c=1, output_c=2, num_filters=64)\n",
    "        else:\n",
    "            self.net_G = net_G\n",
    "        self.net_D = Discriminator(input_c=3, n_down=3, num_filters=64)\n",
    "        self.GANcriterion = GANLoss(gan_mode='vanilla')\n",
    "        self.L1criterion = nn.L1Loss()\n",
    "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "        \n",
    "        self.net_G.to(device)\n",
    "        self.net_D.to(device)\n",
    "        self.GANcriterion.to(device)\n",
    "    \n",
    "    def set_input(self, data):\n",
    "        self.L = data['L'].to(self.device)   #input olarak L:siyah beyaz görüntü\n",
    "        self.ab = data['ab'].to(self.device) #ab renkli görüntü\n",
    "    \n",
    "    def forward(self):\n",
    "        self.fake_color = self.net_G(self.L)\n",
    "    \n",
    "    def backward_D(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image.detach())\n",
    "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
    "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
    "        real_preds = self.net_D(real_image)\n",
    "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "        self.loss_D.backward()\n",
    "    \n",
    "    def backward_G(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image)\n",
    "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
    "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "        self.loss_G.backward()\n",
    "    \n",
    "    def optimize(self):\n",
    "        self.forward()\n",
    "        self.net_D.train()\n",
    "        self.opt_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.opt_D.step()\n",
    "        \n",
    "        self.net_G.train()\n",
    "        self.opt_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f56f6-00e6-488b-9319-c9ecc5497886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#çıktıların görselleştirme kısmı\n",
    "def visualize(model, data):\n",
    "    model.net_G.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.set_input(data)\n",
    "        model.forward()\n",
    "    model.net_G.train()\n",
    "    fake_color = model.fake_color.detach()\n",
    "    real_color = model.ab\n",
    "    L = model.L\n",
    "    fake_imgs = lab_to_rgb(L, fake_color) #fake resimleri renklendirme\n",
    "    real_imgs = lab_to_rgb(L, real_color) #real resimleri renklendirme\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(3, 5, i + 1)\n",
    "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
    "        ax.imshow(fake_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
    "        ax.imshow(real_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def lab_to_rgb(L, ab): #siyah beyaz için oluşturulan lab görüntülerin rgb renkli görüntülere çevrilmesi\n",
    "    L = (L + 1.) * 50.\n",
    "    ab = ab * 110.\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "    rgb_imgs = []\n",
    "    for img in Lab:\n",
    "        img_rgb = lab2rgb(img)\n",
    "        rgb_imgs.append(img_rgb)\n",
    "    return np.stack(rgb_imgs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac106617-a50b-4355-a595-5fb91420c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eğitim kısmı\n",
    "def train_model(model, train_dataloader, epochs, display_every=30):\n",
    "    data = next(iter(train_dataloader))\n",
    "    for e in range(epochs):\n",
    "        loss_meter_dict = {'loss_D': [], 'loss_G': [], 'loss_G_GAN': [], 'loss_G_L1': []}\n",
    "        for i, data in enumerate(tqdm(train_dataloader)):\n",
    "            model.set_input(data) \n",
    "            model.optimize()\n",
    "            \n",
    "            # kayıp değerlerini kaydetme\n",
    "            loss_meter_dict['loss_D'].append(model.loss_D.item())\n",
    "            loss_meter_dict['loss_G'].append(model.loss_G.item())\n",
    "            loss_meter_dict['loss_G_GAN'].append(model.loss_G_GAN.item())\n",
    "            loss_meter_dict['loss_G_L1'].append(model.loss_G_L1.item())\n",
    "            \n",
    "            if i % display_every == 0:\n",
    "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
    "                print(f\"Iteration {i}/{len(train_dataloader)}\")\n",
    "                print(f\"loss_D: {np.mean(loss_meter_dict['loss_D']):.5f}\")\n",
    "                print(f\"loss_G: {np.mean(loss_meter_dict['loss_G']):.5f}\")\n",
    "                print(f\"loss_G_GAN: {np.mean(loss_meter_dict['loss_G_GAN']):.5f}\")\n",
    "                print(f\"loss_G_L1: {np.mean(loss_meter_dict['loss_G_L1']):.5f}\")\n",
    "                visualize(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c48bb5-52aa-48b8-956b-0f50c795ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MainModel()\n",
    "train_model(model, train_dataloader, epochs=50, display_every=30) #50 epoch ve 50 iterasyonda bir sonuç gösterecek modeli şekilde eğitme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913d0b0-271c-4f53-bdcd-ec76fbbc68b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8aa2a-67be-472a-a18b-5772cf2bdb26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
